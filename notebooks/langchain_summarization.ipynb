{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lanchain : Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Union\n",
    "\n",
    "import arxiv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import umap\n",
    "import yaml\n",
    "from langchain import HuggingFaceHub, LLMChain, PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.schema.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from rich import print\n",
    "from sklearn.cluster import DBSCAN\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    BigBirdPegasusForConditionalGeneration,\n",
    "    PegasusTokenizerFast,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">_CudaDeviceProperties</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'NVIDIA GeForce RTX 3090 Ti'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">major</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #808000; text-decoration-color: #808000\">minor</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #808000; text-decoration-color: #808000\">total_memory</span>=<span style=\"color: #800080; text-decoration-color: #800080\">24563MB</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">multi_processor_count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">84</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35m_CudaDeviceProperties\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'NVIDIA GeForce RTX 3090 Ti'\u001b[0m, \u001b[33mmajor\u001b[0m=\u001b[1;36m8\u001b[0m, \u001b[33mminor\u001b[0m=\u001b[1;36m6\u001b[0m, \u001b[33mtotal_memory\u001b[0m=\u001b[35m24563MB\u001b[0m, \n",
       "\u001b[33mmulti_processor_count\u001b[0m=\u001b[1;36m84\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda:0\":\n",
    "    print(torch.cuda.get_device_properties(device))\n",
    "else:\n",
    "    print(f\"No cuda device found; running on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../conf/local/hf_secrets.yml\", \"r\") as f:\n",
    "    hf_secrets = yaml.load(f, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- Enhancing Network Management Using Code Generated by Large Language Models <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">17:49:15</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span><span style=\"font-weight: bold\">]</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- Enhancing Network Management Using Code Generated by Large Language Models \u001b[1m[\u001b[0m\u001b[1;36m2023\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m17:49:15\u001b[0m+\u001b[1;92m00:00\u001b[0m\u001b[1m]\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Analyzing network topologies and communication graphs plays a crucial role in\n",
       "contemporary network management. However, the absence of a cohesive approach\n",
       "leads to a challenging learning curve, heightened errors, and inefficiencies.\n",
       "In this paper, we introduce a novel approach to facilitate a\n",
       "natural-language-based network management experience, utilizing large language\n",
       "models <span style=\"font-weight: bold\">(</span>LLMs<span style=\"font-weight: bold\">)</span> to generate task-specific code from natural language queries.\n",
       "This method tackles the challenges of explainability, scalability, and privacy\n",
       "by allowing network operators to inspect the generated code, eliminating the\n",
       "need to share network data with LLMs, and concentrating on application-specific\n",
       "requests combined with general program synthesis techniques. We design and\n",
       "evaluate a prototype system using benchmark applications, showcasing high\n",
       "accuracy, cost-effectiveness, and the potential for further enhancements using\n",
       "complementary program synthesis techniques.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Analyzing network topologies and communication graphs plays a crucial role in\n",
       "contemporary network management. However, the absence of a cohesive approach\n",
       "leads to a challenging learning curve, heightened errors, and inefficiencies.\n",
       "In this paper, we introduce a novel approach to facilitate a\n",
       "natural-language-based network management experience, utilizing large language\n",
       "models \u001b[1m(\u001b[0mLLMs\u001b[1m)\u001b[0m to generate task-specific code from natural language queries.\n",
       "This method tackles the challenges of explainability, scalability, and privacy\n",
       "by allowing network operators to inspect the generated code, eliminating the\n",
       "need to share network data with LLMs, and concentrating on application-specific\n",
       "requests combined with general program synthesis techniques. We design and\n",
       "evaluate a prototype system using benchmark applications, showcasing high\n",
       "accuracy, cost-effectiveness, and the potential for further enhancements using\n",
       "complementary program synthesis techniques.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">--- A Large Language Model Enhanced Conversational Recommender System <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">16:30:44</span>+<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">00:00</span><span style=\"font-weight: bold\">]</span> ---\n",
       "</pre>\n"
      ],
      "text/plain": [
       "--- A Large Language Model Enhanced Conversational Recommender System \u001b[1m[\u001b[0m\u001b[1;36m2023\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m16:30:44\u001b[0m+\u001b[1;92m00:00\u001b[0m\u001b[1m]\u001b[0m ---\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Conversational recommender systems <span style=\"font-weight: bold\">(</span>CRSs<span style=\"font-weight: bold\">)</span> aim to recommend high-quality items\n",
       "to users through a dialogue interface. It usually contains multiple sub-tasks,\n",
       "such as user preference elicitation, recommendation, explanation, and item\n",
       "information search. To develop effective CRSs, there are some challenges: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "how to properly manage sub-tasks; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> how to effectively solve different\n",
       "sub-tasks; and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)</span> how to correctly generate responses that interact with users.\n",
       "Recently, Large Language Models <span style=\"font-weight: bold\">(</span>LLMs<span style=\"font-weight: bold\">)</span> have exhibited an unprecedented ability\n",
       "to reason and generate, presenting a new opportunity to develop more powerful\n",
       "CRSs. In this work, we propose a new LLM-based CRS, referred to as LLMCRS, to\n",
       "address the above challenges. For sub-task management, we leverage the\n",
       "reasoning ability of LLM to effectively manage sub-task. For sub-task solving,\n",
       "we collaborate LLM with expert models of different sub-tasks to achieve the\n",
       "enhanced performance. For response generation, we utilize the generation\n",
       "ability of LLM as a language interface to better interact with users.\n",
       "Specifically, LLMCRS divides the workflow into four stages: sub-task detection,\n",
       "model matching, sub-task execution, and response generation. LLMCRS also\n",
       "designs schema-based instruction, demonstration-based instruction, dynamic\n",
       "sub-task and model matching, and summary-based generation to instruct LLM to\n",
       "generate desired results in the workflow. Finally, to adapt LLM to\n",
       "conversational recommendations, we also propose to fine-tune LLM with\n",
       "reinforcement learning from CRSs performance feedback, referred to as RLPF.\n",
       "Experimental results on benchmark datasets show that LLMCRS with RLPF\n",
       "outperforms the existing methods.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Conversational recommender systems \u001b[1m(\u001b[0mCRSs\u001b[1m)\u001b[0m aim to recommend high-quality items\n",
       "to users through a dialogue interface. It usually contains multiple sub-tasks,\n",
       "such as user preference elicitation, recommendation, explanation, and item\n",
       "information search. To develop effective CRSs, there are some challenges: \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "how to properly manage sub-tasks; \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m how to effectively solve different\n",
       "sub-tasks; and \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m how to correctly generate responses that interact with users.\n",
       "Recently, Large Language Models \u001b[1m(\u001b[0mLLMs\u001b[1m)\u001b[0m have exhibited an unprecedented ability\n",
       "to reason and generate, presenting a new opportunity to develop more powerful\n",
       "CRSs. In this work, we propose a new LLM-based CRS, referred to as LLMCRS, to\n",
       "address the above challenges. For sub-task management, we leverage the\n",
       "reasoning ability of LLM to effectively manage sub-task. For sub-task solving,\n",
       "we collaborate LLM with expert models of different sub-tasks to achieve the\n",
       "enhanced performance. For response generation, we utilize the generation\n",
       "ability of LLM as a language interface to better interact with users.\n",
       "Specifically, LLMCRS divides the workflow into four stages: sub-task detection,\n",
       "model matching, sub-task execution, and response generation. LLMCRS also\n",
       "designs schema-based instruction, demonstration-based instruction, dynamic\n",
       "sub-task and model matching, and summary-based generation to instruct LLM to\n",
       "generate desired results in the workflow. Finally, to adapt LLM to\n",
       "conversational recommendations, we also propose to fine-tune LLM with\n",
       "reinforcement learning from CRSs performance feedback, referred to as RLPF.\n",
       "Experimental results on benchmark datasets show that LLMCRS with RLPF\n",
       "outperforms the existing methods.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run search query on arxiv\n",
    "search = arxiv.Search(\n",
    "    query=\"ti:LLM OR (ti:LARGE AND ti:LANGUAGE AND ti:MODEL)\",\n",
    "    max_results=100,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate,\n",
    ")\n",
    "\n",
    "# display some results\n",
    "for result in list(search.results())[:2]:\n",
    "    print(f\"--- {result.title} [{result.published}] ---\")\n",
    "    print(result.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting models to try:\n",
    "* [google/bigbird-pegasus-large-arxiv](https://huggingface.co/google/bigbird-pegasus-large-arxiv)\n",
    "* [allenai/led-large-16384-arxiv](https://huggingface.co/allenai/led-large-16384-arxiv)\n",
    "* [google/pegasus-arxiv](https://huggingface.co/google/pegasus-arxiv)\n",
    "* [facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn) (very interesting summarization results from that one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting links for embeddings & langchain:\n",
    "* [HuggingFaceBgeEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceBgeEmbeddings.html?highlight=device)\n",
    "* [HuggingFaceEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceEmbeddings.html?highlight=device)\n",
    "* [HuggingFaceInstructEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.huggingface.HuggingFaceInstructEmbeddings.html?highlight=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_name = \"google/bigbird-pegasus-large-arxiv\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention type 'block_sparse' is not possible if sequence_length: 158 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n"
     ]
    }
   ],
   "source": [
    "# get abstract\n",
    "result = next(search.results())\n",
    "summary = result.summary\n",
    "\n",
    "# feed-forward pass\n",
    "inputs = tokenizer([summary], max_length=4096, return_tensors=\"pt\", truncation=True)\n",
    "outputs = model(**inputs, return_dict=True)\n",
    "\n",
    "# Generate Summary\n",
    "# summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=15)\n",
    "# model_summary = tokenizer.batch_decode(summary_ids,\n",
    "# skip_special_tokens=True,\n",
    "# clean_up_tokenization_spaces=False)[0]\n",
    "# print(f\"model_summary: '{model_summary}'\")\n",
    "\n",
    "# Retrieve embedding\n",
    "cls_token_embed = outputs.encoder_last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_pegasus(\n",
    "    input_text: Union[str, List[str]],\n",
    "    model: BigBirdPegasusForConditionalGeneration,\n",
    "    tokenizer: PegasusTokenizerFast,\n",
    "    batch_size: Optional[int] = None,\n",
    "    device: str = \"cpu\",\n",
    ") -> Union[np.ndarray, torch.Tensor]:\n",
    "    model = model.to(device)\n",
    "\n",
    "    dim = model.config.hidden_size\n",
    "\n",
    "    if isinstance(input_text, str):\n",
    "        inputs = tokenizer(\n",
    "            [input_text],\n",
    "            max_length=4096,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "        )\n",
    "        outputs = model(**inputs.to(device), return_dict=True)\n",
    "        cls_token_embeds = outputs.encoder_last_hidden_state[:, 0, :]\n",
    "\n",
    "        del outputs\n",
    "        del inputs\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    else:\n",
    "        if batch_size is not None:\n",
    "            indices = list(range(0, len(input_text), batch_size)) + [None]\n",
    "            cls_token_embeds = torch.empty((0, dim), device=device)\n",
    "\n",
    "            for i in range(len(indices) - 1):\n",
    "                input_text_i = input_text[indices[i] : indices[i + 1]]\n",
    "                inputs_i = tokenizer(\n",
    "                    input_text_i,\n",
    "                    max_length=4096,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                )\n",
    "                outputs_i = model(**inputs_i.to(device), return_dict=True)\n",
    "                cls_token_embeds_i = outputs_i.encoder_last_hidden_state[:, 0, :]\n",
    "                cls_token_embeds = torch.cat((cls_token_embeds, cls_token_embeds_i), dim=0)\n",
    "\n",
    "                del outputs_i\n",
    "                del inputs_i\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        else:\n",
    "            inputs = tokenizer(input_text, max_length=4096, return_tensors=\"pt\", truncation=True)\n",
    "            outputs = model(**inputs.to(device), return_dict=True)\n",
    "            cls_token_embeds = outputs.encoder_last_hidden_state[:, 0, :]\n",
    "\n",
    "            del outputs\n",
    "            del inputs\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return cls_token_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve abstracts & metadata\n",
    "abstracts = [result.summary for result in search.results()]\n",
    "titles = [result.title for result in search.results()]\n",
    "\n",
    "# embed abstracts\n",
    "with torch.no_grad():\n",
    "    embeddings = embed_pegasus(\n",
    "        input_text=abstracts,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        batch_size=20,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "# convert to numpy\n",
    "if device == \"cpu\":\n",
    "    embeddings = embeddings.numpy()\n",
    "else:\n",
    "    embeddings = embeddings.detach().cpu().numpy()\n",
    "\n",
    "# reduce dimension\n",
    "reducer = umap.UMAP(n_components=2, n_neighbors=5, metric=\"cosine\", min_dist=0.1)\n",
    "umap_coords = reducer.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>umap_0</th>\n",
       "      <th>umap_1</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.530040</td>\n",
       "      <td>-2.340559</td>\n",
       "      <td>Enhancing Network Management Using Code Genera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.170251</td>\n",
       "      <td>4.997292</td>\n",
       "      <td>A Large Language Model Enhanced Conversational...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.014503</td>\n",
       "      <td>9.155603</td>\n",
       "      <td>Improving Zero-Shot Text Matching for Financia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.358764</td>\n",
       "      <td>9.537405</td>\n",
       "      <td>Assessing Student Errors in Experimentation Us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.699078</td>\n",
       "      <td>9.688238</td>\n",
       "      <td>Learning to Guide Human Experts via Personaliz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     umap_0    umap_1                                              title\n",
       "0  6.530040 -2.340559  Enhancing Network Management Using Code Genera...\n",
       "1 -2.170251  4.997292  A Large Language Model Enhanced Conversational...\n",
       "2  4.014503  9.155603  Improving Zero-Shot Text Matching for Financia...\n",
       "3  5.358764  9.537405  Assessing Student Errors in Experimentation Us...\n",
       "4  3.699078  9.688238  Learning to Guide Human Experts via Personaliz..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store results in a dataframe\n",
    "df = pd.DataFrame(data=umap_coords, columns=[f\"umap_{i}\" for i in range(umap_coords.shape[1])])\n",
    "df[\"title\"] = titles\n",
    "\n",
    "# display\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Enhancing Network Management Using Code Generated by Large Language Models"
          ],
          [
           "A Large Language Model Enhanced Conversational Recommender System"
          ],
          [
           "Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models"
          ],
          [
           "Assessing Student Errors in Experimentation Using Artificial Intelligence and Large Language Models: A Comparative Study with Human Raters"
          ],
          [
           "Learning to Guide Human Experts via Personalized Large Language Models"
          ],
          [
           "Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing"
          ],
          [
           "Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?"
          ],
          [
           "Large Language Models for Telecom: Forthcoming Impact on the Industry"
          ],
          [
           "BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents"
          ],
          [
           "You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content"
          ],
          [
           "A Preliminary Evaluation of LLM-Based Fault Localization"
          ],
          [
           "LLM As DBA"
          ],
          [
           "Enhancing Trust in LLM-Based AI Automation Agents: New Considerations and Future Challenges"
          ],
          [
           "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment"
          ],
          [
           "WeaverBird: Empowering Financial Decision-Making with Large Language Model, Knowledge Base, and Search Engine"
          ],
          [
           "RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model"
          ],
          [
           "Metacognitive Prompting Improves Understanding in Large Language Models"
          ],
          [
           "Fixing Rust Compilation Errors using LLMs"
          ],
          [
           "LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation"
          ],
          [
           "An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures"
          ],
          [
           "Extrapolating Large Language Models to Non-English by Aligning Languages"
          ],
          [
           "LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking"
          ],
          [
           "Integrating large language models and active inference to understand eye movements in reading and dyslexia"
          ],
          [
           "Evaluating the Generation Capabilities of Large Chinese Language Models"
          ],
          [
           "Adaptive Intellect Unleashed: The Feasibility of Knowledge Transfer in Large Language Models"
          ],
          [
           "Universal Fuzzing via Large Language Models"
          ],
          [
           "A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology"
          ],
          [
           "Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA"
          ],
          [
           "Benchmarking LLM powered Chatbots: Methods and Metrics"
          ],
          [
           "Accelerating LLM Inference with Staged Speculative Decoding"
          ],
          [
           "Learning Evaluation Models from Large Language Models for Sequence Generation"
          ],
          [
           "Comparing Color Similarity Structures between Humans and LLMs via Unsupervised Alignment"
          ],
          [
           "Cumulative Reasoning with Large Language Models"
          ],
          [
           "AutoPCF: Efficient Product Carbon Footprint Accounting with Large Language Models"
          ],
          [
           "Large Language Model Prompt Chaining for Long Legal Document Classification"
          ],
          [
           "DataTales: Investigating the use of Large Language Models for Authoring Data-Driven Articles"
          ],
          [
           "Gentopia: A Collaborative Platform for Tool-Augmented LLMs"
          ],
          [
           "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation"
          ],
          [
           "Continual Pre-Training of Large Language Models: How to (re)warm your model?"
          ],
          [
           "NEOLAF, an LLM-powered neural-symbolic cognitive architecture"
          ],
          [
           "Simple synthetic data reduces sycophancy in large language models"
          ],
          [
           "Evaluating and Explaining Large Language Models for Code Using Syntactic Structures"
          ],
          [
           "Extracting detailed oncologic history and treatment plan from medical oncology notes with large language models"
          ],
          [
           "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models"
          ],
          [
           "AgentBench: Evaluating LLMs as Agents"
          ],
          [
           "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench"
          ],
          [
           "Mondrian: Prompt Abstraction Attack Against Large Language Models for Cheaper API Pricing"
          ],
          [
           "Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue"
          ],
          [
           "TPTU: Task Planning and Tool Usage of Large Language Model-based AI Agents"
          ],
          [
           "Heterogeneous Knowledge Fusion: A Novel Approach for Personalized Recommendation via LLM"
          ],
          [
           "Quantifying the Impact of Large Language Models on Collective Opinion Dynamics"
          ],
          [
           "LoRA-FA: Memory-efficient Low-rank Adaptation for Large Language Models Fine-tuning"
          ],
          [
           "Studying Large Language Model Generalization with Influence Functions"
          ],
          [
           "UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition"
          ],
          [
           "Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies"
          ],
          [
           "Understanding the Effectiveness of Large Language Models in Code Translation"
          ],
          [
           "Embedding-based Retrieval with LLM for Effective Agriculture Information Extracting from Unstructured Data"
          ],
          [
           "LARCH: Large Language Model-based Automatic Readme Creation with Heuristics"
          ],
          [
           "Pre-Trained Large Language Models for Industrial Control"
          ],
          [
           "SAPIEN: Affective Virtual Agents Powered by Large Language Models"
          ],
          [
           "LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation"
          ],
          [
           "EduChat: A Large-Scale Language Model-based Chatbot System for Intelligent Education"
          ],
          [
           "Legal Summarisation through LLMs: The PRODIGIT Project"
          ],
          [
           "Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology"
          ],
          [
           "The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations"
          ],
          [
           "Improving Requirements Completeness: Automated Assistance through Large Language Models"
          ],
          [
           "From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?"
          ],
          [
           "Reasoning in Large Language Models Through Symbolic Math Word Problems"
          ],
          [
           "Wider and Deeper LLM Networks are Fairer LLM Evaluators"
          ],
          [
           "ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation"
          ],
          [
           "The Capability of Large Language Models to Measure Psychiatric Functioning"
          ],
          [
           "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models"
          ],
          [
           "Does Correction Remain An Problem For Large Language Models?"
          ],
          [
           "Supply chain emission estimation using large language models"
          ],
          [
           "Local Large Language Models for Complex Structured Medical Tasks"
          ],
          [
           "Baby's CoThought: Leveraging Large Language Models for Enhanced Reasoning in Compact Models"
          ],
          [
           "Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors"
          ],
          [
           "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"
          ],
          [
           "ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders"
          ],
          [
           "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models"
          ],
          [
           "Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation"
          ],
          [
           "Towards Understanding the Capability of Large Language Models on Code Clone Detection: A Survey"
          ],
          [
           "LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs"
          ],
          [
           "LISA: Reasoning Segmentation via Large Language Model"
          ],
          [
           "CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code"
          ],
          [
           "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models"
          ],
          [
           "Structural Embeddings of Tools for Large Language Models"
          ],
          [
           "SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning"
          ],
          [
           "Ethical Considerations and Policy Implications for Large Language Models: Guiding Responsible Development and Deployment"
          ],
          [
           "Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models"
          ],
          [
           "The Hitchhiker's Guide to Program Analysis: A Journey with Large Language Models"
          ],
          [
           "A Composable Just-In-Time Programming Framework with LLMs and FBP"
          ],
          [
           "Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?"
          ],
          [
           "Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?"
          ],
          [
           "Virtual Prompt Injection for Instruction-Tuned Large Language Models"
          ],
          [
           "HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution"
          ],
          [
           "Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc"
          ],
          [
           "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"
          ],
          [
           "Ontology engineering with Large Language Models"
          ],
          [
           "Large Language Models for Education: Grading Open-Ended Questions Using ChatGPT"
          ]
         ],
         "hovertemplate": "umap_0=%{x}<br>umap_1=%{y}<br>title=%{customdata[0]}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          6.530040264129639,
          -2.1702511310577393,
          4.01450252532959,
          5.358763694763184,
          3.699078321456909,
          -2.976104259490967,
          5.229384899139404,
          4.719038009643555,
          5.542819976806641,
          -1.5490953922271729,
          4.596954822540283,
          4.628996849060059,
          6.420806407928467,
          -1.750051498413086,
          1.988043189048767,
          4.990100860595703,
          5.366405963897705,
          4.429505825042725,
          5.6132073402404785,
          5.827606201171875,
          7.727252960205078,
          5.87087869644165,
          5.0766215324401855,
          3.481534004211426,
          1.7957093715667725,
          -3.3744211196899414,
          -2.4576892852783203,
          1.866742491722107,
          5.541905879974365,
          2.791311740875244,
          5.537457466125488,
          5.144856929779053,
          4.447766304016113,
          4.007003307342529,
          5.215328216552734,
          3.737429141998291,
          6.73262882232666,
          4.643906116485596,
          5.650031566619873,
          3.4860575199127197,
          7.772377490997315,
          -3.0429110527038574,
          -2.6774003505706787,
          5.849033832550049,
          4.964715480804443,
          -2.8529131412506104,
          -1.8927459716796875,
          1.8706673383712769,
          6.5763630867004395,
          3.1389715671539307,
          -2.815807580947876,
          5.886237144470215,
          7.588542938232422,
          -2.5384247303009033,
          4.834705829620361,
          -3.263864278793335,
          5.258301258087158,
          5.82916259765625,
          6.176811695098877,
          3.2736005783081055,
          -1.4940831661224363,
          2.169306755065918,
          3.4543118476867676,
          5.419947624206543,
          4.962640285491943,
          -1.0681443214416504,
          4.450528621673584,
          6.070700168609619,
          -3.286851644515991,
          -2.06559681892395,
          4.63538122177124,
          6.382848739624023,
          3.937863349914551,
          5.140617847442627,
          6.096430778503418,
          2.2907724380493164,
          -1.126068115234375,
          3.2022335529327393,
          -1.2096534967422483,
          2.0403285026550293,
          2.566739559173584,
          7.74448299407959,
          2.34606409072876,
          7.786567687988281,
          2.1417407989501953,
          -1.0112919807434082,
          2.681467056274414,
          2.4304206371307373,
          3.2416577339172363,
          -0.8072789311408997,
          2.5703999996185303,
          2.4326019287109375,
          6.885446071624756,
          2.5070207118988037,
          -1.1158758401870728,
          2.743485689163208,
          2.2767255306243896,
          -3.1879165172576904,
          3.10780668258667,
          3.1958632469177246
         ],
         "xaxis": "x",
         "y": [
          -2.3405590057373047,
          4.997291564941406,
          9.155603408813477,
          9.537405014038086,
          9.688238143920898,
          6.177210807800293,
          -2.59251070022583,
          8.439322471618652,
          8.233290672302246,
          4.665704250335693,
          -3.2104618549346924,
          -3.2900729179382324,
          -2.203273296356201,
          5.173754692077637,
          9.007824897766112,
          -2.8623337745666504,
          8.09516429901123,
          9.315469741821287,
          8.008383750915527,
          -2.5572140216827393,
          -0.5332627296447754,
          9.062270164489746,
          9.2704496383667,
          9.56513786315918,
          9.19491958618164,
          6.571227073669434,
          5.073528289794922,
          9.304168701171877,
          8.106579780578613,
          7.978372573852539,
          8.848979949951172,
          8.81676197052002,
          9.747221946716309,
          9.679311752319336,
          9.417778968811035,
          8.085947036743164,
          -2.273110866546631,
          9.49539566040039,
          -2.687344551086426,
          8.022446632385254,
          -0.48860040307044983,
          6.234375953674316,
          5.314328193664551,
          -2.5393424034118652,
          8.552179336547852,
          5.9870924949646,
          4.699917316436768,
          7.983862400054932,
          -2.165416955947876,
          8.20664119720459,
          5.544580936431885,
          8.36963176727295,
          -0.700458824634552,
          5.171299934387207,
          -3.034144639968872,
          6.4683380126953125,
          -2.684384822845459,
          9.118578910827637,
          8.800989151000977,
          8.338035583496094,
          4.648055076599121,
          7.6952667236328125,
          8.457026481628418,
          -2.6224536895751953,
          -2.897355556488037,
          5.0553717613220215,
          -3.1625442504882812,
          8.664729118347168,
          6.434185981750488,
          4.809395790100098,
          8.657004356384277,
          -2.1742308139801025,
          9.409189224243164,
          8.214072227478027,
          8.890350341796875,
          7.844930648803711,
          5.143299579620361,
          8.512337684631348,
          4.589839935302734,
          8.36936092376709,
          10.34095859527588,
          -0.5146082639694214,
          10.29040241241455,
          -0.4731464684009552,
          7.90410041809082,
          4.6981401443481445,
          9.626083374023438,
          10.152142524719238,
          9.11378574371338,
          4.778591156005859,
          9.552693367004396,
          8.819478034973145,
          -2.251582384109497,
          10.10214614868164,
          4.507296085357666,
          10.255208969116213,
          10.14607048034668,
          6.345563888549805,
          9.016680717468262,
          9.967110633850098
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "umap_0"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "umap_1"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# viz\n",
    "fig = px.scatter(df, x=\"umap_0\", y=\"umap_1\", hover_data=\"title\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Enhancing Network Management Using Code Generated by Large Language Models"
          ],
          [
           "A Large Language Model Enhanced Conversational Recommender System"
          ],
          [
           "Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models"
          ],
          [
           "Assessing Student Errors in Experimentation Using Artificial Intelligence and Large Language Models: A Comparative Study with Human Raters"
          ],
          [
           "Learning to Guide Human Experts via Personalized Large Language Models"
          ],
          [
           "Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing"
          ],
          [
           "Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?"
          ],
          [
           "Large Language Models for Telecom: Forthcoming Impact on the Industry"
          ],
          [
           "BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents"
          ],
          [
           "You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content"
          ],
          [
           "A Preliminary Evaluation of LLM-Based Fault Localization"
          ],
          [
           "LLM As DBA"
          ],
          [
           "Enhancing Trust in LLM-Based AI Automation Agents: New Considerations and Future Challenges"
          ],
          [
           "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment"
          ],
          [
           "WeaverBird: Empowering Financial Decision-Making with Large Language Model, Knowledge Base, and Search Engine"
          ],
          [
           "RTLLM: An Open-Source Benchmark for Design RTL Generation with Large Language Model"
          ],
          [
           "Metacognitive Prompting Improves Understanding in Large Language Models"
          ],
          [
           "Fixing Rust Compilation Errors using LLMs"
          ],
          [
           "LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation"
          ],
          [
           "An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures"
          ],
          [
           "Extrapolating Large Language Models to Non-English by Aligning Languages"
          ],
          [
           "LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking"
          ],
          [
           "Integrating large language models and active inference to understand eye movements in reading and dyslexia"
          ],
          [
           "Evaluating the Generation Capabilities of Large Chinese Language Models"
          ],
          [
           "Adaptive Intellect Unleashed: The Feasibility of Knowledge Transfer in Large Language Models"
          ],
          [
           "Universal Fuzzing via Large Language Models"
          ],
          [
           "A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology"
          ],
          [
           "Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA"
          ],
          [
           "Benchmarking LLM powered Chatbots: Methods and Metrics"
          ],
          [
           "Accelerating LLM Inference with Staged Speculative Decoding"
          ],
          [
           "Learning Evaluation Models from Large Language Models for Sequence Generation"
          ],
          [
           "Comparing Color Similarity Structures between Humans and LLMs via Unsupervised Alignment"
          ],
          [
           "Cumulative Reasoning with Large Language Models"
          ],
          [
           "AutoPCF: Efficient Product Carbon Footprint Accounting with Large Language Models"
          ],
          [
           "Large Language Model Prompt Chaining for Long Legal Document Classification"
          ],
          [
           "DataTales: Investigating the use of Large Language Models for Authoring Data-Driven Articles"
          ],
          [
           "Gentopia: A Collaborative Platform for Tool-Augmented LLMs"
          ],
          [
           "AgentSims: An Open-Source Sandbox for Large Language Model Evaluation"
          ],
          [
           "Continual Pre-Training of Large Language Models: How to (re)warm your model?"
          ],
          [
           "NEOLAF, an LLM-powered neural-symbolic cognitive architecture"
          ],
          [
           "Simple synthetic data reduces sycophancy in large language models"
          ],
          [
           "Evaluating and Explaining Large Language Models for Code Using Syntactic Structures"
          ],
          [
           "Extracting detailed oncologic history and treatment plan from medical oncology notes with large language models"
          ],
          [
           "\"Do Anything Now\": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models"
          ],
          [
           "AgentBench: Evaluating LLMs as Agents"
          ],
          [
           "Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using EmotionBench"
          ],
          [
           "Mondrian: Prompt Abstraction Attack Against Large Language Models for Cheaper API Pricing"
          ],
          [
           "Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue"
          ],
          [
           "TPTU: Task Planning and Tool Usage of Large Language Model-based AI Agents"
          ],
          [
           "Heterogeneous Knowledge Fusion: A Novel Approach for Personalized Recommendation via LLM"
          ],
          [
           "Quantifying the Impact of Large Language Models on Collective Opinion Dynamics"
          ],
          [
           "LoRA-FA: Memory-efficient Low-rank Adaptation for Large Language Models Fine-tuning"
          ],
          [
           "Studying Large Language Model Generalization with Influence Functions"
          ],
          [
           "UniversalNER: Targeted Distillation from Large Language Models for Open Named Entity Recognition"
          ],
          [
           "Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies"
          ],
          [
           "Understanding the Effectiveness of Large Language Models in Code Translation"
          ],
          [
           "Embedding-based Retrieval with LLM for Effective Agriculture Information Extracting from Unstructured Data"
          ],
          [
           "LARCH: Large Language Model-based Automatic Readme Creation with Heuristics"
          ],
          [
           "Pre-Trained Large Language Models for Industrial Control"
          ],
          [
           "SAPIEN: Affective Virtual Agents Powered by Large Language Models"
          ],
          [
           "LLM is Like a Box of Chocolates: the Non-determinism of ChatGPT in Code Generation"
          ],
          [
           "EduChat: A Large-Scale Language Model-based Chatbot System for Intelligent Education"
          ],
          [
           "Legal Summarisation through LLMs: The PRODIGIT Project"
          ],
          [
           "Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology"
          ],
          [
           "The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations"
          ],
          [
           "Improving Requirements Completeness: Automated Assistance through Large Language Models"
          ],
          [
           "From Prompt Injections to SQL Injection Attacks: How Protected is Your LLM-Integrated Web Application?"
          ],
          [
           "Reasoning in Large Language Models Through Symbolic Math Word Problems"
          ],
          [
           "Wider and Deeper LLM Networks are Fairer LLM Evaluators"
          ],
          [
           "ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation"
          ],
          [
           "The Capability of Large Language Models to Measure Psychiatric Functioning"
          ],
          [
           "Scaling Relationship on Learning Mathematical Reasoning with Large Language Models"
          ],
          [
           "Does Correction Remain An Problem For Large Language Models?"
          ],
          [
           "Supply chain emission estimation using large language models"
          ],
          [
           "Local Large Language Models for Complex Structured Medical Tasks"
          ],
          [
           "Baby's CoThought: Leveraging Large Language Models for Enhanced Reasoning in Compact Models"
          ],
          [
           "Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors"
          ],
          [
           "OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"
          ],
          [
           "ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders"
          ],
          [
           "XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models"
          ],
          [
           "Evaluating Instruction-Tuned Large Language Models on Code Comprehension and Generation"
          ],
          [
           "Towards Understanding the Capability of Large Language Models on Code Clone Detection: A Survey"
          ],
          [
           "LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs"
          ],
          [
           "LISA: Reasoning Segmentation via Large Language Model"
          ],
          [
           "CodeBPE: Investigating Subtokenization Options for Large Language Model Pretraining on Source Code"
          ],
          [
           "Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models"
          ],
          [
           "Structural Embeddings of Tools for Large Language Models"
          ],
          [
           "SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning"
          ],
          [
           "Ethical Considerations and Policy Implications for Large Language Models: Guiding Responsible Development and Deployment"
          ],
          [
           "Skills-in-Context Prompting: Unlocking Compositionality in Large Language Models"
          ],
          [
           "The Hitchhiker's Guide to Program Analysis: A Journey with Large Language Models"
          ],
          [
           "A Composable Just-In-Time Programming Framework with LLMs and FBP"
          ],
          [
           "Generative Models as a Complex Systems Science: How can we make sense of large language model behavior?"
          ],
          [
           "Predicting Perfect Quality Segments in MT Output with Fine-Tuned OpenAI LLM: Is it possible to capture editing distance patterns from historical data?"
          ],
          [
           "Virtual Prompt Injection for Instruction-Tuned Large Language Models"
          ],
          [
           "HAGRID: A Human-LLM Collaborative Dataset for Generative Information-Seeking with Attribution"
          ],
          [
           "Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc"
          ],
          [
           "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs"
          ],
          [
           "Ontology engineering with Large Language Models"
          ],
          [
           "Large Language Models for Education: Grading Open-Ended Questions Using ChatGPT"
          ]
         ],
         "hovertemplate": "umap_0=%{x}<br>umap_1=%{y}<br>title=%{customdata[0]}<br>cluster=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": [
           0,
           1,
           2,
           2,
           2,
           1,
           0,
           2,
           2,
           1,
           0,
           0,
           0,
           1,
           2,
           0,
           2,
           2,
           2,
           0,
           3,
           2,
           2,
           2,
           2,
           1,
           1,
           2,
           2,
           2,
           2,
           2,
           2,
           2,
           2,
           2,
           0,
           2,
           0,
           2,
           3,
           1,
           1,
           0,
           2,
           1,
           1,
           2,
           0,
           2,
           1,
           2,
           3,
           1,
           0,
           1,
           0,
           2,
           2,
           2,
           1,
           2,
           2,
           0,
           0,
           1,
           0,
           2,
           1,
           1,
           2,
           0,
           2,
           2,
           2,
           2,
           1,
           2,
           1,
           2,
           2,
           3,
           2,
           3,
           2,
           1,
           2,
           2,
           2,
           1,
           2,
           2,
           0,
           2,
           1,
           2,
           2,
           1,
           2,
           2
          ],
          "coloraxis": "coloraxis",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          6.530040264129639,
          -2.1702511310577393,
          4.01450252532959,
          5.358763694763184,
          3.699078321456909,
          -2.976104259490967,
          5.229384899139404,
          4.719038009643555,
          5.542819976806641,
          -1.5490953922271729,
          4.596954822540283,
          4.628996849060059,
          6.420806407928467,
          -1.750051498413086,
          1.988043189048767,
          4.990100860595703,
          5.366405963897705,
          4.429505825042725,
          5.6132073402404785,
          5.827606201171875,
          7.727252960205078,
          5.87087869644165,
          5.0766215324401855,
          3.481534004211426,
          1.7957093715667725,
          -3.3744211196899414,
          -2.4576892852783203,
          1.866742491722107,
          5.541905879974365,
          2.791311740875244,
          5.537457466125488,
          5.144856929779053,
          4.447766304016113,
          4.007003307342529,
          5.215328216552734,
          3.737429141998291,
          6.73262882232666,
          4.643906116485596,
          5.650031566619873,
          3.4860575199127197,
          7.772377490997315,
          -3.0429110527038574,
          -2.6774003505706787,
          5.849033832550049,
          4.964715480804443,
          -2.8529131412506104,
          -1.8927459716796875,
          1.8706673383712769,
          6.5763630867004395,
          3.1389715671539307,
          -2.815807580947876,
          5.886237144470215,
          7.588542938232422,
          -2.5384247303009033,
          4.834705829620361,
          -3.263864278793335,
          5.258301258087158,
          5.82916259765625,
          6.176811695098877,
          3.2736005783081055,
          -1.4940831661224363,
          2.169306755065918,
          3.4543118476867676,
          5.419947624206543,
          4.962640285491943,
          -1.0681443214416504,
          4.450528621673584,
          6.070700168609619,
          -3.286851644515991,
          -2.06559681892395,
          4.63538122177124,
          6.382848739624023,
          3.937863349914551,
          5.140617847442627,
          6.096430778503418,
          2.2907724380493164,
          -1.126068115234375,
          3.2022335529327393,
          -1.2096534967422483,
          2.0403285026550293,
          2.566739559173584,
          7.74448299407959,
          2.34606409072876,
          7.786567687988281,
          2.1417407989501953,
          -1.0112919807434082,
          2.681467056274414,
          2.4304206371307373,
          3.2416577339172363,
          -0.8072789311408997,
          2.5703999996185303,
          2.4326019287109375,
          6.885446071624756,
          2.5070207118988037,
          -1.1158758401870728,
          2.743485689163208,
          2.2767255306243896,
          -3.1879165172576904,
          3.10780668258667,
          3.1958632469177246
         ],
         "xaxis": "x",
         "y": [
          -2.3405590057373047,
          4.997291564941406,
          9.155603408813477,
          9.537405014038086,
          9.688238143920898,
          6.177210807800293,
          -2.59251070022583,
          8.439322471618652,
          8.233290672302246,
          4.665704250335693,
          -3.2104618549346924,
          -3.2900729179382324,
          -2.203273296356201,
          5.173754692077637,
          9.007824897766112,
          -2.8623337745666504,
          8.09516429901123,
          9.315469741821287,
          8.008383750915527,
          -2.5572140216827393,
          -0.5332627296447754,
          9.062270164489746,
          9.2704496383667,
          9.56513786315918,
          9.19491958618164,
          6.571227073669434,
          5.073528289794922,
          9.304168701171877,
          8.106579780578613,
          7.978372573852539,
          8.848979949951172,
          8.81676197052002,
          9.747221946716309,
          9.679311752319336,
          9.417778968811035,
          8.085947036743164,
          -2.273110866546631,
          9.49539566040039,
          -2.687344551086426,
          8.022446632385254,
          -0.48860040307044983,
          6.234375953674316,
          5.314328193664551,
          -2.5393424034118652,
          8.552179336547852,
          5.9870924949646,
          4.699917316436768,
          7.983862400054932,
          -2.165416955947876,
          8.20664119720459,
          5.544580936431885,
          8.36963176727295,
          -0.700458824634552,
          5.171299934387207,
          -3.034144639968872,
          6.4683380126953125,
          -2.684384822845459,
          9.118578910827637,
          8.800989151000977,
          8.338035583496094,
          4.648055076599121,
          7.6952667236328125,
          8.457026481628418,
          -2.6224536895751953,
          -2.897355556488037,
          5.0553717613220215,
          -3.1625442504882812,
          8.664729118347168,
          6.434185981750488,
          4.809395790100098,
          8.657004356384277,
          -2.1742308139801025,
          9.409189224243164,
          8.214072227478027,
          8.890350341796875,
          7.844930648803711,
          5.143299579620361,
          8.512337684631348,
          4.589839935302734,
          8.36936092376709,
          10.34095859527588,
          -0.5146082639694214,
          10.29040241241455,
          -0.4731464684009552,
          7.90410041809082,
          4.6981401443481445,
          9.626083374023438,
          10.152142524719238,
          9.11378574371338,
          4.778591156005859,
          9.552693367004396,
          8.819478034973145,
          -2.251582384109497,
          10.10214614868164,
          4.507296085357666,
          10.255208969116213,
          10.14607048034668,
          6.345563888549805,
          9.016680717468262,
          9.967110633850098
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "cluster"
          }
         },
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "umap_0"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "umap_1"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# clustering with (H)DBSCAN\n",
    "\n",
    "clusterer = DBSCAN(eps=0.8)\n",
    "clusterer.fit(df[[col for col in df.columns if \"umap\" in col]])\n",
    "df[\"cluster\"] = clusterer.labels_\n",
    "\n",
    "# viz\n",
    "fig = px.scatter(df, x=\"umap_0\", y=\"umap_1\", hover_data=\"title\", color=\"cluster\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize clusters of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting links:\n",
    "* [https://python.langchain.com/docs/integrations/retrievers/arxiv](https://python.langchain.com/docs/integrations/retrievers/arxiv)\n",
    "* [https://python.langchain.com/docs/additional_resources/tutorials](https://python.langchain.com/docs/additional_resources/tutorials)\n",
    "* [https://python.langchain.com/docs/use_cases/summarization](https://python.langchain.com/docs/use_cases/summarization)\n",
    "* [https://huggingface.co/facebook/bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)\n",
    "* [https://python.langchain.com/docs/integrations/llms/openllm](https://python.langchain.com/docs/integrations/llms/openllm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "# See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
    "repo_id = \"facebook/bart-large-cnn\"\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=repo_id,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.15,\n",
    "        \"max_length\": 100,\n",
    "        # \"device\": device,\n",
    "    },\n",
    "    huggingfacehub_api_token=hf_secrets[\"hf_hub_token\"],\n",
    ")\n",
    "\n",
    "\n",
    "# question = \"Who won the FIFA World Cup in the year 1994? \"\n",
    "# template = \"\"\"\n",
    "# Question: {question}\n",
    "\n",
    "# Answer:\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "# print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Map reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build docs\n",
    "\n",
    "cluster_idx = 0\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=abstracts[i],\n",
    "        metadata={\"title\": titles[i]},\n",
    "    )\n",
    "    for i in range(len(titles))\n",
    "    if df.loc[df[\"title\"] == titles[i], \"cluster\"].values[0] == cluster_idx\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Analyzing network topologies and communication graphs plays a crucial role in\\ncontemporary </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">network management. However, the absence of a cohesive approach\\nleads to a challenging learning curve, heightened </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">errors, and inefficiencies.\\nIn this paper, we introduce a novel approach to facilitate a\\nnatural-language-based </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">network management experience, utilizing large language\\nmodels (LLMs) to generate task-specific code from natural </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">language queries.\\nThis method tackles the challenges of explainability, scalability, and privacy\\nby allowing </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">network operators to inspect the generated code, eliminating the\\nneed to share network data with LLMs, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">concentrating on application-specific\\nrequests combined with general program synthesis techniques. We design </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and\\nevaluate a prototype system using benchmark applications, showcasing high\\naccuracy, cost-effectiveness, and </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the potential for further enhancements using\\ncomplementary program synthesis techniques.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Enhancing Network Management Using Code Generated by Large Language Models'</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Large Language Models (LLMs) could enhance access to the legal system.\\nHowever, empirical </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">research on their effectiveness in conducting legal tasks is\\nscant. We study securities cases involving </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">cryptocurrencies as one of numerous\\ncontexts where AI could support the legal process, studying LLMs' </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">legal\\nreasoning and drafting capabilities. We examine whether a) an LLM can\\naccurately determine which laws are </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">potentially being violated from a fact\\npattern, and b) whether there is a difference in juror decision-making </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">based on\\ncomplaints written by a lawyer compared to an LLM. We feed fact patterns from\\nreal-life cases to GPT-3.5</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">and evaluate its ability to determine correct\\npotential violations from the scenario and exclude spurious </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">violations. Second,\\nwe had mock jurors assess complaints written by the LLM and lawyers. GPT-3.5's\\nlegal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">reasoning skills proved weak, though we expect improvement in future\\nmodels, particularly given the violations it </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">suggested tended to be correct (it\\nmerely missed additional, correct violations). GPT-3.5 performed better </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">at\\nlegal drafting, and jurors' decisions were not statistically significantly\\nassociated with the author of the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">document upon which they based their\\ndecisions. Because LLMs cannot satisfactorily conduct legal reasoning </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tasks,\\nthey would be unable to replace lawyers at this stage. However, their drafting\\nskills (though, perhaps, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">still inferior to lawyers), could provide access to\\njustice for more individuals by reducing the cost of legal </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">services. Our\\nresearch is the first to systematically study LLMs' legal drafting and\\nreasoning capabilities in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">litigation, as well as in securities law and\\ncryptocurrency-related misconduct.\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'Analyzing network topologies and communication graphs plays a crucial role in\\ncontemporary \u001b[0m\n",
       "\u001b[32mnetwork management. However, the absence of a cohesive approach\\nleads to a challenging learning curve, heightened \u001b[0m\n",
       "\u001b[32merrors, and inefficiencies.\\nIn this paper, we introduce a novel approach to facilitate a\\nnatural-language-based \u001b[0m\n",
       "\u001b[32mnetwork management experience, utilizing large language\\nmodels \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m to generate task-specific code from natural \u001b[0m\n",
       "\u001b[32mlanguage queries.\\nThis method tackles the challenges of explainability, scalability, and privacy\\nby allowing \u001b[0m\n",
       "\u001b[32mnetwork operators to inspect the generated code, eliminating the\\nneed to share network data with LLMs, and \u001b[0m\n",
       "\u001b[32mconcentrating on application-specific\\nrequests combined with general program synthesis techniques. We design \u001b[0m\n",
       "\u001b[32mand\\nevaluate a prototype system using benchmark applications, showcasing high\\naccuracy, cost-effectiveness, and \u001b[0m\n",
       "\u001b[32mthe potential for further enhancements using\\ncomplementary program synthesis techniques.'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'title'\u001b[0m: \u001b[32m'Enhancing Network Management Using Code Generated by Large Language Models'\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m\"Large\u001b[0m\u001b[32m Language Models \u001b[0m\u001b[32m(\u001b[0m\u001b[32mLLMs\u001b[0m\u001b[32m)\u001b[0m\u001b[32m could enhance access to the legal system.\\nHowever, empirical \u001b[0m\n",
       "\u001b[32mresearch on their effectiveness in conducting legal tasks is\\nscant. We study securities cases involving \u001b[0m\n",
       "\u001b[32mcryptocurrencies as one of numerous\\ncontexts where AI could support the legal process, studying LLMs' \u001b[0m\n",
       "\u001b[32mlegal\\nreasoning and drafting capabilities. We examine whether a\u001b[0m\u001b[32m)\u001b[0m\u001b[32m an LLM can\\naccurately determine which laws are \u001b[0m\n",
       "\u001b[32mpotentially being violated from a fact\\npattern, and b\u001b[0m\u001b[32m)\u001b[0m\u001b[32m whether there is a difference in juror decision-making \u001b[0m\n",
       "\u001b[32mbased on\\ncomplaints written by a lawyer compared to an LLM. We feed fact patterns from\\nreal-life cases to GPT-3.5\u001b[0m\n",
       "\u001b[32mand evaluate its ability to determine correct\\npotential violations from the scenario and exclude spurious \u001b[0m\n",
       "\u001b[32mviolations. Second,\\nwe had mock jurors assess complaints written by the LLM and lawyers. GPT-3.5's\\nlegal \u001b[0m\n",
       "\u001b[32mreasoning skills proved weak, though we expect improvement in future\\nmodels, particularly given the violations it \u001b[0m\n",
       "\u001b[32msuggested tended to be correct \u001b[0m\u001b[32m(\u001b[0m\u001b[32mit\\nmerely missed additional, correct violations\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. GPT-3.5 performed better \u001b[0m\n",
       "\u001b[32mat\\nlegal drafting, and jurors' decisions were not statistically significantly\\nassociated with the author of the \u001b[0m\n",
       "\u001b[32mdocument upon which they based their\\ndecisions. Because LLMs cannot satisfactorily conduct legal reasoning \u001b[0m\n",
       "\u001b[32mtasks,\\nthey would be unable to replace lawyers at this stage. However, their drafting\\nskills \u001b[0m\u001b[32m(\u001b[0m\u001b[32mthough, perhaps, \u001b[0m\n",
       "\u001b[32mstill inferior to lawyers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, could provide access to\\njustice for more individuals by reducing the cost of legal \u001b[0m\n",
       "\u001b[32mservices. Our\\nresearch is the first to systematically study LLMs' legal drafting and\\nreasoning capabilities in \u001b[0m\n",
       "\u001b[32mlitigation, as well as in securities law and\\ncryptocurrency-related misconduct.\"\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(docs[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{docs}\n",
    "Based on this list of docs, please identify the main themes\n",
    "Helpful Answer:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "{doc_summaries}\n",
    "Take these and distill it into a final, consolidated summary of the main themes.\n",
    "Helpful Answer:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(llm_chain=reduce_chain, document_variable_name=\"doc_summaries\")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=0)\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(map_reduce_chain.run(split_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Refine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
