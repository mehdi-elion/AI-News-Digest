{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random, sys\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from rich import print\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import umap\n",
    "from sklearn.cluster import KMeans, HDBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import torch\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU availability\n",
    "sys.path.append(\"../\")\n",
    "from src.ai_news_digest.utils import check_gpu_availability, create_run_folder\n",
    "from src.ai_news_digest.steps.clustering_utils import (\n",
    "    clustering_pipeline,\n",
    "    entropy,\n",
    "    grid_search_umap_projection,\n",
    "    grid_search_clustering,\n",
    ")\n",
    "import src.ai_news_digest.steps.load_news_corpus as lnc\n",
    "import src.ai_news_digest.steps.load_arxiv_corpus as lac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set random seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "random.seed(123)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = check_gpu_availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG_PATH = \"../conf/base/cluster_bench_models.yml\"\n",
    "DATA_PATH = \"../data/03_primary/arxiv_dict_2023-11-06_00-22-42.json\"\n",
    "\n",
    "MODEL_KWARGS = {\"device\": device}\n",
    "ENCODE_KWARGS = {\n",
    "    \"normalize_embeddings\": True,\n",
    "    \"batch_size\": 16,\n",
    "    \"output_value\": \"sentence_embedding\",\n",
    "    \"convert_to_numpy\": True,\n",
    "    \"show_progress_bar\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_INFO_DICT = \"data/03_primary/arxiv_dict_2023-11-06_00-22-42.json\"\n",
    "MODEL_ID = \"BAAI/bge-small-en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Clustering Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load data\n",
    "# with open(DATA_PATH, \"r\") as f:\n",
    "#     info_dict = json.load(f)[\"results\"]\n",
    "# logger.info(f\"Successfully loaded prepared data from : {DATA_PATH}\")\n",
    "\n",
    "# # retrieve abstracts, titles, dates & paper IDs\n",
    "# df_data = pd.DataFrame(info_dict).transpose()\n",
    "\n",
    "# # display\n",
    "# df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query \n",
    "res_gnews = lnc.load_news_gnews(\n",
    "    keywords=\"semi conductors\",\n",
    "    language=\"en\",\n",
    "    period=\"90d\",\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    exclude_websites=[],\n",
    "    max_results=300,\n",
    "    override_content=True,\n",
    "    use_logs=False,\n",
    "    standardize=True,\n",
    ")\n",
    "\n",
    "# store in dataframe\n",
    "df_data = pd.DataFrame({d[\"url\"]: d for d in res_gnews}).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.dropna(subset=[\"content\"], inplace=True)\n",
    "df_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=MODEL_ID,\n",
    "    model_kwargs={\"device\": device},\n",
    "    encode_kwargs=ENCODE_KWARGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embeddings\n",
    "# embeddings = np.array(hf.embed_documents(df_data[\"abstract\"]))\n",
    "embeddings = np.array(hf.embed_documents(df_data[\"content\"]))\n",
    "\n",
    "# store embeddings in a dataframe\n",
    "df_embed = pd.DataFrame(\n",
    "    data=embeddings, \n",
    "    columns=[f\"embed_{i}\" for i in range(embeddings.shape[1])],\n",
    "    index=df_data.index\n",
    ")\n",
    "\n",
    "# display\n",
    "df_embed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set umap params\n",
    "umap_kwargs = {\n",
    "    \"n_neighbors\": 5,\n",
    "    \"min_dist\": 0.001,\n",
    "    \"n_components\": 2,\n",
    "    \"metric\": \"cosine\",\n",
    "}\n",
    "\n",
    "# instanciate umap projector\n",
    "reducer = umap.UMAP(random_state=123, **umap_kwargs)\n",
    "\n",
    "# project data\n",
    "umap_proj = reducer.fit_transform(df_embed)\n",
    "\n",
    "# normalize umap coords\n",
    "umap_proj = (umap_proj - umap_proj.min(axis=0)) / (umap_proj.max(axis=0) - umap_proj.min(axis=0))\n",
    "\n",
    "# store in a dataframe with metadata\n",
    "df_umap = pd.DataFrame(columns=[f\"umap_{i}\" for i in range(umap_proj.shape[1])], data=umap_proj)\n",
    "df_umap = pd.concat((df_umap, df_data.reset_index(names=[\"ID\"])), axis=1)\n",
    "\n",
    "# display\n",
    "df_umap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster = df_umap[[col for col in df_umap.columns if \"umap\" in col]]\n",
    "\n",
    "clustering = HDBSCAN(\n",
    "    min_cluster_size=10, \n",
    "    min_samples=3, \n",
    "    max_cluster_size=None, \n",
    "    cluster_selection_epsilon=0.05\n",
    ")\n",
    "clustering.fit(X_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz\n",
    "df_umap[\"cluster\"] = [str(elt) for elt in clustering.labels_]\n",
    "df_umap[\"noise\"] = [int(elt==-1) for elt in clustering.labels_]\n",
    "fig = px.scatter(\n",
    "    df_umap,\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    hover_data=[\n",
    "        \"title\",\n",
    "        \"ID\",\n",
    "    ],\n",
    "    color=\"cluster\",\n",
    "    symbol=\"noise\",\n",
    "    # color_continuous_scale=px.colors.qualitative.D3,\n",
    "    category_orders={\"cluster\": list(np.sort(pd.unique(clustering.labels_)).astype(str))},\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy ↓\n",
    "entropy(X_cluster.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette ↑\n",
    "silhouette_score(X_cluster, df_umap[\"cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactored Clustering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_kwargs = {    \n",
    "    \"min_cluster_size\": 10, \n",
    "    \"min_samples\": 3, \n",
    "    \"max_cluster_size\": None, \n",
    "    \"cluster_selection_epsilon\": 0.05,\n",
    "}\n",
    "\n",
    "umap_kwargs = {\n",
    "    \"n_neighbors\": 5,\n",
    "    \"min_dist\": 0.1,\n",
    "    \"n_components\": 2,\n",
    "    \"metric\": \"cosine\",\n",
    "}\n",
    "\n",
    "df_umap, clustering = clustering_pipeline(\n",
    "    df_embed,\n",
    "    umap_kwargs,\n",
    "    clustering_kwargs,\n",
    "    random_state=123,\n",
    "    df_data=df_data,\n",
    ")\n",
    "\n",
    "X_cluster = df_umap[[c for c in df_umap.columns if \"umap_\" in c]]\n",
    "\n",
    "# Silhouette ↑\n",
    "print(f\" Silhouette ↑ = {silhouette_score(X_cluster, df_umap['cluster'])}\")\n",
    "\n",
    "# Entropy ↓\n",
    "print(f\" Entropy ↓ = {entropy(X_cluster.values)}\")\n",
    "\n",
    "# viz\n",
    "df_umap[\"cluster\"] = [str(elt) for elt in clustering.labels_]\n",
    "df_umap[\"noise\"] = [int(elt==-1) for elt in clustering.labels_]\n",
    "fig = px.scatter(\n",
    "    df_umap,\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    hover_data=[\n",
    "        \"title\",\n",
    "        # \"ID\",\n",
    "    ],\n",
    "    color=\"cluster\",\n",
    "    symbol=\"noise\",\n",
    "    # color_continuous_scale=px.colors.qualitative.D3,\n",
    "    category_orders={\"cluster\": list(np.sort(pd.unique(clustering.labels_)).astype(str))},\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search over projection and clustering parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize UMAP Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import product\n",
    "from tqdm.contrib.itertools import product\n",
    "\n",
    "clustering_grid = {\n",
    "    \"min_cluster_size\": [3, 5, 10, 15], \n",
    "    \"min_samples\": [3, 5, 10], \n",
    "    \"max_cluster_size\": [\n",
    "        None, \n",
    "        15, \n",
    "        25, \n",
    "        40,\n",
    "    ], \n",
    "    \"cluster_selection_epsilon\": [\n",
    "        # 0.0, \n",
    "        # 0.05, \n",
    "        # 0.0,\n",
    "        # 0.001,\n",
    "        # 0.01,\n",
    "        0.05,\n",
    "        0.1,    \n",
    "        0.5,    \n",
    "    ],\n",
    "}\n",
    "\n",
    "umap_grid = {\n",
    "    \"n_neighbors\": [\n",
    "        # 2, \n",
    "        4, \n",
    "        8, \n",
    "        10,\n",
    "    ],\n",
    "    \"min_dist\": [0.001, 0.01, 0.1, 0.5],\n",
    "    \"n_components\": [2],\n",
    "    \"metric\": [\"cosine\"],\n",
    "    \"init\": [\"random\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_entropy, best_umap_kwargs, df_umap_search = grid_search_umap_projection(\n",
    "    umap_grid=umap_grid,\n",
    "    df_embed=df_embed,\n",
    "    random_state=123,\n",
    "    df_data=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_umap_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(df_umap_search)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_silhouette, best_clustering_kwargs, df_clustering_search = grid_search_clustering(\n",
    "    clustering_grid=clustering_grid,\n",
    "    df_embed=df_embed,\n",
    "    umap_kwargs=best_umap_kwargs,\n",
    "    random_state=123,\n",
    "    df_data=df_data,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering_search.sort_values(by=\"Silhouette ↑\").tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clustering_search[\"Silhouette ↑\"].sort_values().reset_index(drop=True).plot(figsize=(8,3), grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_matrix(df_clustering_search, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Optimized Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_umap, clustering = clustering_pipeline(\n",
    "    df_embed,\n",
    "    best_umap_kwargs,\n",
    "    best_clustering_kwargs,\n",
    "    random_state=123,\n",
    "    df_data=df_data,\n",
    ")\n",
    "\n",
    "X_cluster = df_umap[[c for c in df_umap.columns if \"umap_\" in c]]\n",
    "\n",
    "# Silhouette ↑\n",
    "print(f\" Silhouette ↑ = {silhouette_score(X_cluster, df_umap['cluster'])}\")\n",
    "\n",
    "# Entropy ↓\n",
    "print(f\" Entropy ↓ = {entropy(X_cluster.values)}\")\n",
    "\n",
    "# viz\n",
    "df_umap[\"cluster\"] = [str(elt) for elt in clustering.labels_]\n",
    "df_umap[\"noise\"] = [int(elt==-1) for elt in clustering.labels_]\n",
    "fig = px.scatter(\n",
    "    df_umap,\n",
    "    x=\"umap_0\",\n",
    "    y=\"umap_1\",\n",
    "    hover_data=[\n",
    "        \"title\",\n",
    "        # \"ID\",\n",
    "    ],\n",
    "    color=\"cluster\",\n",
    "    symbol=\"noise\",\n",
    "    category_orders={\"cluster\": list(np.sort(pd.unique(clustering.labels_)).astype(str))},\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
