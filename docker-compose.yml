services:
  qdrant:
    image: qdrant/qdrant:latest
    restart: always
    container_name: qdrant
    ports:
      - 6333:6333
    expose:
      - 6333
      - 6335
    configs:
      - source: qdrant_config
        target: /qdrant/config/config.yaml
    volumes:
      - ./qdrant_data:/qdrant_data

  gen_api:
   image: vllm/vllm-openai:latest
   environment:
     - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
   command: ["--model", "${GEN_MODEL_ID}"]
   deploy:
     resources:
       reservations:
         devices:
           - driver: nvidia
             count: 1
             capabilities: [gpu]
   restart: unless-stopped
   container_name: gen_api
   ports:
     - 8000:8000
   volumes:
     - ~/.cache/huggingface:/root/.cache/huggingface

  embed_api:
   image: ghcr.io/huggingface/text-embeddings-inference
   environment:
     - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
   command: ["--model-id", "${EMBED_MODEL_ID}", "--revision", "${EMBED_REVISION}"]
   deploy:
     resources:
       reservations:
         devices:
           - driver: nvidia
             count: 1
             capabilities: [gpu]
   container_name: embed_api
   ports:
     - 8081:80
   expose:
     - 8081
   volumes:
     - ./data/06_models/embed_api:/data

configs:
  qdrant_config:
    file: conf/base/qdrant_config.yaml
