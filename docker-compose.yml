services:
  qdrant:
    image: qdrant/qdrant:latest
    restart: always
    container_name: qdrant
    ports:
      - 6333:6333
    expose:
      - 6333
      - 6335
    configs:
      - source: qdrant_config
        target: /qdrant/config/config.yaml
    volumes:
      - ./qdrant_data:/qdrant_data

  gen_api:
    image: ghcr.io/huggingface/text-generation-inference:1.3
    env:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - MODEL_ID={$GEN_MODEL_ID:-meta-llama/Llama-2-7b-chat-hf}
    command: ["--model_id", "${MODEL_ID}", "--quantize", "eetq"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 20g
    restart: unless-stopped
    container_name: gen_api
    ports:
      - 8080:80
    expose:
      - 8080
    volumes:
      - ./data/06_models/gen_api:/data

  embed_api:
    image: ghcr.io/huggingface/text-embeddings-inference:0.6
    env:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - MODEL_ID=${EMBED_MODEL_ID:-BAAI/bge-small-en}
      - REVISION=${EMBED_REVISION:-main}
    command: ["--model-id", "${MODEL_ID}", "--revision", "${REVISION}"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    container_name: embed_api
    ports:
      - 8081:80
    expose:
      - 8081
    volumes:
      - ./data/06_models/embed_api:/data

configs:
  qdrant_config:
    file: conf/base/qdrant_config.yaml
